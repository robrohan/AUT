{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df2c1cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (0.3.11)\n",
      "Requirement already satisfied: transformers in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (4.56.1)\n",
      "Requirement already satisfied: pandas in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.2.6)\n",
      "Requirement already satisfied: tqdm in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-text-splitters) (0.3.75)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: filelock in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.24.0)\n",
      "Requirement already satisfied: anyio in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-text-splitters transformers pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d108f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ba4f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Load a tokenizer for a BERT-like model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    # length_function=len,\n",
    "    length_function=count_tokens,\n",
    "    # is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "456840f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(text):\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    chunks = []\n",
    "    for i,t in enumerate(texts):\n",
    "        # replace newlines with spaces this can help keep word boundires\n",
    "        chunks.append(t.page_content.replace(\"\\n\", \" \"))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6d0b26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Count: 100\n",
      "Negitive Count: 100\n"
     ]
    }
   ],
   "source": [
    "df_p = pd.read_csv('./datasets/positive_w_text.csv', delimiter='|')\n",
    "df_n = pd.read_csv('./datasets/negitive_w_text.csv', delimiter='|')\n",
    "\n",
    "print(f'Positive Count: {len(df_p)}')\n",
    "print(f'Negitive Count: {len(df_n)}')\n",
    "\n",
    "df_p = df_p.drop(columns=[\"SUBJECT_ID\"])\n",
    "df_n = df_n.drop(columns=[\"SUBJECT_ID\"])\n",
    "\n",
    "df = pd.concat([df_p, df_n], ignore_index=True)\n",
    "# df.reset_index(inplace=True)\n",
    "\n",
    "# This shuffles the dataframe, but in a non-reproducable way\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# Instead shuffle dataframe, but in a reproducable way\n",
    "SEED=42\n",
    "np.random.seed(SEED)\n",
    "idx = df.index.to_list()\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "df = df.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a9457f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intellectual Developmental Disorders', 'Communication Disorders', 'Autism Spectrum Disorder', 'Attention-Deficit/Hyperactivity Disorder', 'Specific Learning Disorder', 'Motor Disorders', 'Other Neurodevelo mental Disorders p', 'Schizophrenia Spectrum and Other Psychotic Disorders', 'Catatonia', 'Bipolar and Related Disorders', 'Depressive Disorders', 'Anxiety Disorders', 'Obsessive-Compulsive and Related Disorders', 'Trauma- and Stressor-Related Disorders', 'Dissociative Disorders', 'Somatic Symptom and Related Disorders', 'Feeding and Eating Disorders', 'Elimination Disorders', 'Sleep-Wake Disorders', 'Breathing-Related Sleep Disorders', 'Parasomnias', 'Sexual Dysfunctions', 'Gender Dysphoria', 'Disruptive, Impulse-Control, and Conduct Disorders', 'Neurocognitive Disorders', 'Personality Disorders', 'Cluster A Personality Disorders', 'Cluster B Personality Disorders', 'Cluster C Personalit Disorders y', 'Other Personality Disorders', 'Paraphilic Disorders', 'Other Mental Disorders and Additional Codes', 'Additional Codes', 'Medication-Induced Movement Disorders and Other Adverse Effects of Medication', 'Other Conditions That May Be a Focus of Clinical Attention']\n",
      "[{'name': 'Distilbert', 'url': 'http://t2v-transformers:8080', 'schema': 'DSMDistilbert'}, {'name': 'Roberta', 'url': 'http://t2v-transformers-drobert:8080', 'schema': 'DSMRoberta'}, {'name': 'Biobert', 'url': 'http://t2v-transformers-biobert:8080', 'schema': 'DSMBiobert'}, {'name': 'Clinicalbert', 'url': 'http://t2v-transformers-clicbert:8080', 'schema': 'DSMClinicalbert'}]\n"
     ]
    }
   ],
   "source": [
    "from tables import classes, schema_dicts\n",
    "print(classes)\n",
    "print(schema_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e912c",
   "metadata": {},
   "source": [
    "**Schema Index**\n",
    "| ID | Model | Port |\n",
    "|----|-------|------|\n",
    "| 0 | Distilbert | 9090 |\n",
    "| 1 | Roberta | 9091 |\n",
    "| 2 | Biobert | 9092 |\n",
    "| 3 | Clinicalbert | 9093 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43f99cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 20 200\n"
     ]
    }
   ],
   "source": [
    "# Which BERT model to use\n",
    "schema_index = 2\n",
    "# When using vector distance, this is the farthest\n",
    "# a vector can be to be considered\n",
    "max_avg_distance = 20\n",
    "# Total number of documents to process\n",
    "# For example, we grab 2000 positive, 2000 negitive\n",
    "# shuffle them, and then process this many total\n",
    "test_range = len(df) # 2000\n",
    "\n",
    "print(schema_index, max_avg_distance, test_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f70362f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "\n",
    "def query_top_x(text, limit=1, max_distance=20):\n",
    "    client = weaviate.connect_to_local()\n",
    "    res = None\n",
    "    try:\n",
    "        collection = client.collections.use(schema_dicts[schema_index][\"schema\"])\n",
    "\n",
    "        results = collection.query.near_text(\n",
    "            # Because near_text is a purely vector search, we get a\n",
    "            # distance and no score\n",
    "            return_metadata=wvc.query.MetadataQuery(\n",
    "                score=True, explain_score=True, distance=True, certainty=True\n",
    "            ),\n",
    "            query=text,\n",
    "            limit=limit\n",
    "        )\n",
    "        for r in results.objects:\n",
    "            if r.metadata.distance < max_distance:\n",
    "                res = [classes.index(r.properties['title']), r.metadata.distance]\n",
    "\n",
    "        return res\n",
    "    finally:\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d437978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_document(s, max_dist=10):\n",
    "    cat = {}\n",
    "    top_results = []\n",
    "\n",
    "    for i, _ in enumerate(classes):\n",
    "        cat[i] = {\"count\":0, \"distance\":0}\n",
    "\n",
    "    for _, d in enumerate(s):\n",
    "        cat[d[0]][\"count\"] += 1\n",
    "        cat[d[0]][\"distance\"] += d[1]\n",
    "        cat[d[0]][\"avg\"] = cat[d[0]][\"distance\"] / cat[d[0]][\"count\"]\n",
    "\n",
    "    for i, _ in enumerate(classes):\n",
    "        if cat[i][\"count\"] > 0 and cat[i][\"distance\"] < max_dist:\n",
    "            top_results.append([cat[i][\"avg\"], i])\n",
    "\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "results = []\n",
    "for i in tqdm(range(test_range)):\n",
    "    text = str(df.iloc[i][\"chart_text\"])\n",
    "\n",
    "    if type(text) == str:\n",
    "        chart_chunks = chunk(text[:500000])\n",
    "        scores = []\n",
    "        for c in chart_chunks:\n",
    "            d = query_top_x(c, 5)\n",
    "            if d is not None:\n",
    "                scores.append(d)\n",
    "\n",
    "        top = np.array(score_document(scores, max_avg_distance))\n",
    "        top = np.sort(top, axis=0)\n",
    "\n",
    "        results.append([i, df.iloc[i][\"class_number\"], top])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2ad0f",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Correct answer in the top 5 - just to get a view of the results. See 5_results.ipynb for the full results process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60269a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct top 5    0.145\n",
      "Correct category 0.515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>original</th>\n",
       "      <th>predict</th>\n",
       "      <th>top5</th>\n",
       "      <th>inTop5</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[[5.893804550170898, 12.0], [5.986674308776855...</td>\n",
       "      <td>[12.0, 16.0, 19.0, 20.0, 23.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[[5.628378629684448, 7.0], [5.900808572769165,...</td>\n",
       "      <td>[7.0, 9.0, 17.0, 18.0, 20.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.7681050300598145, 3.0], [6.807843685150146...</td>\n",
       "      <td>[3.0, 5.0, 13.0, 19.0, 20.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.181078910827637, 7.0], [6.7290167808532715...</td>\n",
       "      <td>[7.0, 17.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.62813138961792, 11.0]]</td>\n",
       "      <td>[11.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.66018009185791, 3.0], [6.949618101119995, ...</td>\n",
       "      <td>[3.0, 5.0, 16.0, 18.0, 21.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.232017993927002, 7.0], [6.535416126251221,...</td>\n",
       "      <td>[7.0, 10.0, 13.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>[[12.789074897766113, 33.0]]</td>\n",
       "      <td>[33.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.800507545471191, 12.0], [7.424792289733887...</td>\n",
       "      <td>[12.0, 15.0, 16.0, 26.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record  original                                            predict  \\\n",
       "0         0        10  [[5.893804550170898, 12.0], [5.986674308776855...   \n",
       "1         1        10  [[5.628378629684448, 7.0], [5.900808572769165,...   \n",
       "2         2        10  [[6.7681050300598145, 3.0], [6.807843685150146...   \n",
       "3         3         0  [[6.181078910827637, 7.0], [6.7290167808532715...   \n",
       "4         4         0                                                 []   \n",
       "..      ...       ...                                                ...   \n",
       "195     195         0                         [[6.62813138961792, 11.0]]   \n",
       "196     196        10  [[6.66018009185791, 3.0], [6.949618101119995, ...   \n",
       "197     197        10  [[6.232017993927002, 7.0], [6.535416126251221,...   \n",
       "198     198         0                       [[12.789074897766113, 33.0]]   \n",
       "199     199         0  [[6.800507545471191, 12.0], [7.424792289733887...   \n",
       "\n",
       "                               top5  inTop5  correct  \n",
       "0    [12.0, 16.0, 19.0, 20.0, 23.0]       0        0  \n",
       "1      [7.0, 9.0, 17.0, 18.0, 20.0]       0        0  \n",
       "2      [3.0, 5.0, 13.0, 19.0, 20.0]       0        0  \n",
       "3                       [7.0, 17.0]       0        1  \n",
       "4                                []       0        1  \n",
       "..                              ...     ...      ...  \n",
       "195                          [11.0]       0        0  \n",
       "196    [3.0, 5.0, 16.0, 18.0, 21.0]       0        0  \n",
       "197               [7.0, 10.0, 13.0]       1        1  \n",
       "198                          [33.0]       0        1  \n",
       "199        [12.0, 15.0, 16.0, 26.0]       0        1  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results, columns=[\"record\", \"original\", \"predict\"])\n",
    "\n",
    "def top5(x):\n",
    "    return np.array([y[1] for i,y in enumerate(x) if i < 5])\n",
    "\n",
    "def in_top_5(orig, top5):\n",
    "    return 1 if orig in top5 else 0\n",
    "\n",
    "def correct_predict(orig, top5):\n",
    "    if orig == 0 and 11 not in top5 and 10 not in top5:\n",
    "        return 1\n",
    "    return 1 if orig in top5 else 0\n",
    "\n",
    "df_results['top5'] = df_results['predict'].map(top5)\n",
    "df_results['inTop5'] = df_results.apply(lambda x: in_top_5(orig=x['original'], top5=x['top5']), axis=1)\n",
    "df_results['correct'] = df_results.apply(lambda x: correct_predict(orig=x['original'], top5=x['top5']), axis=1)\n",
    "\n",
    "print(f\"Correct top 5    {df_results['inTop5'].sum() / test_range}\")\n",
    "print(f\"Correct category {df_results['correct'].sum() / test_range}\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c66da",
   "metadata": {},
   "source": [
    "### Future: Mean Reciprocal Rank (MRR)\n",
    "\n",
    "The position of the first correct result is important\n",
    "\n",
    "For each query, find the rank of the first correct result. The Reciprocal Rank (RR) is $1 / rank$. MRR is the average RR across all queries.\n",
    "\n",
    "Example: Suppose you have 3 queries:\n",
    "- Query 1: Correct result is ranked 1st → RR = 1/1 = 1.0\n",
    "- Query 2: Correct result is ranked 3rd → RR = 1/3 ≈ 0.33\n",
    "- Query 3: Correct result is ranked 2nd → RR = 1/2 = 0.5\n",
    "\n",
    "$$\n",
    "MRR = (1.0 + 0.33 + 0.5) / 3 ≈ 0.61\n",
    "$$\n",
    "\n",
    "$$\n",
    "MRR = \\frac{1}{∣Q∣} \\sum_{i=1}^{∣Q∣}\\frac{​1}{rank_i}\n",
    "$$\n",
    "\n",
    "A good Mean Reciprocal Rank (MRR) value typically ranges from 0.6 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR: 0.07725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>original</th>\n",
       "      <th>predict</th>\n",
       "      <th>top5</th>\n",
       "      <th>inTop5</th>\n",
       "      <th>correct</th>\n",
       "      <th>mmr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[[5.893804550170898, 12.0], [5.986674308776855...</td>\n",
       "      <td>[12.0, 16.0, 19.0, 20.0, 23.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[[5.628378629684448, 7.0], [5.900808572769165,...</td>\n",
       "      <td>[7.0, 9.0, 17.0, 18.0, 20.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.7681050300598145, 3.0], [6.807843685150146...</td>\n",
       "      <td>[3.0, 5.0, 13.0, 19.0, 20.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.181078910827637, 7.0], [6.7290167808532715...</td>\n",
       "      <td>[7.0, 17.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.62813138961792, 11.0]]</td>\n",
       "      <td>[11.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.66018009185791, 3.0], [6.949618101119995, ...</td>\n",
       "      <td>[3.0, 5.0, 16.0, 18.0, 21.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.232017993927002, 7.0], [6.535416126251221,...</td>\n",
       "      <td>[7.0, 10.0, 13.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>[[12.789074897766113, 33.0]]</td>\n",
       "      <td>[33.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.800507545471191, 12.0], [7.424792289733887...</td>\n",
       "      <td>[12.0, 15.0, 16.0, 26.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record  original                                            predict  \\\n",
       "0         0        10  [[5.893804550170898, 12.0], [5.986674308776855...   \n",
       "1         1        10  [[5.628378629684448, 7.0], [5.900808572769165,...   \n",
       "2         2        10  [[6.7681050300598145, 3.0], [6.807843685150146...   \n",
       "3         3         0  [[6.181078910827637, 7.0], [6.7290167808532715...   \n",
       "4         4         0                                                 []   \n",
       "..      ...       ...                                                ...   \n",
       "195     195         0                         [[6.62813138961792, 11.0]]   \n",
       "196     196        10  [[6.66018009185791, 3.0], [6.949618101119995, ...   \n",
       "197     197        10  [[6.232017993927002, 7.0], [6.535416126251221,...   \n",
       "198     198         0                       [[12.789074897766113, 33.0]]   \n",
       "199     199         0  [[6.800507545471191, 12.0], [7.424792289733887...   \n",
       "\n",
       "                               top5  inTop5  correct  mmr  \n",
       "0    [12.0, 16.0, 19.0, 20.0, 23.0]       0        0  0.0  \n",
       "1      [7.0, 9.0, 17.0, 18.0, 20.0]       0        0  0.0  \n",
       "2      [3.0, 5.0, 13.0, 19.0, 20.0]       0        0  0.0  \n",
       "3                       [7.0, 17.0]       0        1  0.0  \n",
       "4                                []       0        1  0.0  \n",
       "..                              ...     ...      ...  ...  \n",
       "195                          [11.0]       0        0  0.0  \n",
       "196    [3.0, 5.0, 16.0, 18.0, 21.0]       0        0  0.0  \n",
       "197               [7.0, 10.0, 13.0]       1        1  0.5  \n",
       "198                          [33.0]       0        1  0.0  \n",
       "199        [12.0, 15.0, 16.0, 26.0]       0        1  0.0  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mmr(orig, top5):\n",
    "    idx = np.where(top5 == orig)[0]\n",
    "    return (1/(idx+1) if idx.size != 0 else [0])[0]\n",
    "\n",
    "df_results['mmr'] = df_results.apply(lambda x: mmr(orig=x['original'], top5=x['top5']), axis=1)\n",
    "\n",
    "print(f\"MMR: {df_results['mmr'].sum() / len(df)}\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(f\"datasets/{schema_index}_{max_avg_distance}_{test_range}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
