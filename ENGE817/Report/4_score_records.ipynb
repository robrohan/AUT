{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2c1cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (0.3.11)\n",
      "Requirement already satisfied: transformers in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (4.56.1)\n",
      "Requirement already satisfied: pandas in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-text-splitters) (0.3.75)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: filelock in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.24.0)\n",
      "Requirement already satisfied: anyio in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-text-splitters transformers pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d108f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba4f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Load a tokenizer for a BERT-like model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    # length_function=len,\n",
    "    length_function=count_tokens,\n",
    "    # is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "456840f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(text):\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    chunks = []\n",
    "    for i,t in enumerate(texts):\n",
    "        # replace newlines with spaces this can help keep word boundires\n",
    "        chunks.append(t.page_content.replace(\"\\n\", \" \"))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d0b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/text_classes.csv', delimiter='|')\n",
    "df = df.sample(frac=1)\n",
    "# 4353\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9457f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intellectual Developmental Disorders', 'Communication Disorders', 'Autism Spectrum Disorder', 'Attention-Deficit/Hyperactivity Disorder', 'Specific Learning Disorder', 'Motor Disorders', 'Other Neurodevelo mental Disorders p', 'Schizophrenia Spectrum and Other Psychotic Disorders', 'Catatonia', 'Bipolar and Related Disorders', 'Depressive Disorders', 'Anxiety Disorders', 'Obsessive-Compulsive and Related Disorders', 'Trauma- and Stressor-Related Disorders', 'Dissociative Disorders', 'Somatic Symptom and Related Disorders', 'Feeding and Eating Disorders', 'Elimination Disorders', 'Sleep-Wake Disorders', 'Breathing-Related Sleep Disorders', 'Parasomnias', 'Sexual Dysfunctions', 'Gender Dysphoria', 'Disruptive, Impulse-Control, and Conduct Disorders', 'Neurocognitive Disorders', 'Personality Disorders', 'Cluster A Personality Disorders', 'Cluster B Personality Disorders', 'Cluster C Personalit Disorders y', 'Other Personality Disorders', 'Paraphilic Disorders', 'Other Mental Disorders and Additional Codes', 'Additional Codes', 'Medication-Induced Movement Disorders and Other Adverse Effects of Medication', 'Other Conditions That May Be a Focus of Clinical Attention']\n",
      "[{'name': 'Distilbert', 'url': 'http://t2v-transformers:8080', 'schema': 'DSMDistilbert'}, {'name': 'Roberta', 'url': 'http://t2v-transformers-drobert:8080', 'schema': 'DSMRoberta'}, {'name': 'Biobert', 'url': 'http://t2v-transformers-biobert:8080', 'schema': 'DSMBiobert'}, {'name': 'Clinicalbert', 'url': 'http://t2v-transformers-clicbert:8080', 'schema': 'DSMClinicalbert'}]\n"
     ]
    }
   ],
   "source": [
    "from tables import classes, schema_dicts\n",
    "print(classes)\n",
    "print(schema_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f99cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_index = 3\n",
    "max_avg_distance = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70362f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "\n",
    "def query_top_five(text, limit=1, max_distance=20):\n",
    "    client = weaviate.connect_to_local()\n",
    "    res = None\n",
    "    try:\n",
    "        collection = client.collections.use(schema_dicts[schema_index][\"schema\"])\n",
    "\n",
    "        results = collection.query.near_text(\n",
    "            # Because near_text is a purely vector search, we get a\n",
    "            # distance and no score\n",
    "            return_metadata=wvc.query.MetadataQuery(\n",
    "                score=True, explain_score=True, distance=True, certainty=True\n",
    "            ),\n",
    "            query=text,\n",
    "            limit=limit\n",
    "        )\n",
    "        for r in results.objects:\n",
    "            if r.metadata.distance < max_distance:\n",
    "                res = [classes.index(r.properties['title']), r.metadata.distance]\n",
    "\n",
    "        return res\n",
    "    finally:\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6054757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = 1\n",
    "\n",
    "# chart_chunks = chunk(df.iloc[item][\"chart_text\"])\n",
    "# print(f\"Chunks size: {len(chart_chunks)}\")\n",
    "\n",
    "# scores = []\n",
    "# for c in chart_chunks:\n",
    "#     d = query_top_five(c)\n",
    "#     if d is not None:\n",
    "#         scores.append(d)\n",
    "\n",
    "# print(f\"Scores size: {len(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d437978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_document(s, max=10):\n",
    "    cat = {}\n",
    "    top_results = []\n",
    "\n",
    "    for i, _ in enumerate(classes):\n",
    "        cat[i] = {\"count\":0, \"distance\":0}\n",
    "\n",
    "    for _, d in enumerate(s):\n",
    "        cat[d[0]][\"count\"] += 1\n",
    "        cat[d[0]][\"distance\"] += d[1]\n",
    "        cat[d[0]][\"avg\"] = cat[d[0]][\"distance\"] / cat[d[0]][\"count\"]\n",
    "\n",
    "    for i, _ in enumerate(classes):\n",
    "        if cat[i][\"count\"] > 0 and cat[i][\"avg\"] < max:\n",
    "            top_results.append([cat[i][\"avg\"], i])\n",
    "\n",
    "    return top_results\n",
    "\n",
    "# top = np.array(score_document(scores, max_avg_distance))\n",
    "# print(np.sort(top, axis=0))\n",
    "# print('--------------')\n",
    "# print(f'{df.iloc[item][\"class_number\"]:02} {classes[df.iloc[item][\"class_number\"]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06e9f24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks size: 102\n",
      "Chunks size: 23\n",
      "Chunks size: 8\n",
      "Chunks size: 4\n",
      "Chunks size: 24\n",
      "Chunks size: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 480, which is longer than the specified 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks size: 18\n",
      "Chunks size: 48\n",
      "Chunks size: 103\n",
      "Chunks size: 10\n",
      "Chunks size: 45\n",
      "Chunks size: 5\n",
      "Chunks size: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 439, which is longer than the specified 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks size: 29\n",
      "Chunks size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 434, which is longer than the specified 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks size: 21\n",
      "Chunks size: 4\n",
      "Chunks size: 5\n",
      "Chunks size: 52\n",
      "Chunks size: 949\n"
     ]
    }
   ],
   "source": [
    "test_range = 20\n",
    "\n",
    "results = []\n",
    "for i in range(test_range): # 4353//4):\n",
    "    chart_chunks = chunk(df.iloc[i][\"chart_text\"])\n",
    "    print(f\"Chunks size: {len(chart_chunks)}\")\n",
    "\n",
    "    scores = []\n",
    "    for c in chart_chunks:\n",
    "        d = query_top_five(c)\n",
    "        if d is not None:\n",
    "            scores.append(d)\n",
    "\n",
    "    top = np.array(score_document(scores, max_avg_distance))\n",
    "    top = np.sort(top, axis=0)\n",
    "\n",
    "    results.append([i, df.iloc[i][\"class_number\"], top])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60269a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>original</th>\n",
       "      <th>predict</th>\n",
       "      <th>top5</th>\n",
       "      <th>inTop5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.878668573167589, 9.0], [8.774086475372314,...</td>\n",
       "      <td>[9.0, 10.0, 16.0, 17.0, 18.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.601770401000977, 9.0], [9.37295389175415, ...</td>\n",
       "      <td>[9.0, 10.0, 17.0, 18.0, 19.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[[9.353336970011393, 10.0], [10.36445776621500...</td>\n",
       "      <td>[10.0, 23.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>[[7.409327983856201, 18.0], [8.699587345123291...</td>\n",
       "      <td>[18.0, 20.0, 33.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.114090919494629, 9.0], [7.589475750923157,...</td>\n",
       "      <td>[9.0, 16.0, 18.0, 19.0, 23.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.121258926391602, 10.0], [8.127206802368164...</td>\n",
       "      <td>[10.0, 23.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>[[8.195616006851196, 9.0], [8.31314468383789, ...</td>\n",
       "      <td>[9.0, 10.0, 16.0, 23.0, 33.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.679414351781209, 9.0], [8.058435440063477,...</td>\n",
       "      <td>[9.0, 10.0, 12.0, 17.0, 18.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>[[8.35844171408451, 10.0], [8.680580298105875,...</td>\n",
       "      <td>[10.0, 16.0, 18.0, 19.0, 20.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.885260581970215, 10.0], [8.75302004814148,...</td>\n",
       "      <td>[10.0, 18.0, 23.0, 24.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.62782096862793, 9.0], [7.804901599884033, ...</td>\n",
       "      <td>[9.0, 10.0, 16.0, 17.0, 18.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.922219753265381, 9.0], [8.760235786437988,...</td>\n",
       "      <td>[9.0, 10.0, 23.0, 28.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>[[6.697694540023804, 8.0], [7.51682726542155, ...</td>\n",
       "      <td>[8.0, 9.0, 18.0, 20.0, 23.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.636113166809082, 10.0], [9.359113897596087...</td>\n",
       "      <td>[10.0, 16.0, 17.0, 18.0, 19.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.56107759475708, 8.0], [8.553693135579428, ...</td>\n",
       "      <td>[8.0, 10.0, 16.0, 18.0, 23.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.694614887237549, 9.0], [7.9096550941467285...</td>\n",
       "      <td>[9.0, 10.0, 16.0, 18.0, 20.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.154293537139893, 10.0], [8.405153274536133...</td>\n",
       "      <td>[10.0, 18.0, 23.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>[[7.99909241994222, 10.0], [9.019610404968262,...</td>\n",
       "      <td>[10.0, 18.0, 23.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>[[10.016941184089298, 16.0], [10.1735391616821...</td>\n",
       "      <td>[16.0, 18.0, 20.0, 23.0, 24.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>[[7.016827583312988, 3.0], [7.817195415496826,...</td>\n",
       "      <td>[3.0, 5.0, 8.0, 9.0, 10.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    record  original                                            predict  \\\n",
       "0        0        10  [[7.878668573167589, 9.0], [8.774086475372314,...   \n",
       "1        1        10  [[7.601770401000977, 9.0], [9.37295389175415, ...   \n",
       "2        2        10  [[9.353336970011393, 10.0], [10.36445776621500...   \n",
       "3        3        11  [[7.409327983856201, 18.0], [8.699587345123291...   \n",
       "4        4        10  [[7.114090919494629, 9.0], [7.589475750923157,...   \n",
       "5        5        10  [[7.121258926391602, 10.0], [8.127206802368164...   \n",
       "6        6        11  [[8.195616006851196, 9.0], [8.31314468383789, ...   \n",
       "7        7        10  [[7.679414351781209, 9.0], [8.058435440063477,...   \n",
       "8        8        10  [[8.35844171408451, 10.0], [8.680580298105875,...   \n",
       "9        9        10  [[6.885260581970215, 10.0], [8.75302004814148,...   \n",
       "10      10        10  [[7.62782096862793, 9.0], [7.804901599884033, ...   \n",
       "11      11        10  [[7.922219753265381, 9.0], [8.760235786437988,...   \n",
       "12      12        10  [[6.697694540023804, 8.0], [7.51682726542155, ...   \n",
       "13      13        10  [[7.636113166809082, 10.0], [9.359113897596087...   \n",
       "14      14        10  [[7.56107759475708, 8.0], [8.553693135579428, ...   \n",
       "15      15        10  [[7.694614887237549, 9.0], [7.9096550941467285...   \n",
       "16      16        10  [[7.154293537139893, 10.0], [8.405153274536133...   \n",
       "17      17        11  [[7.99909241994222, 10.0], [9.019610404968262,...   \n",
       "18      18        10  [[10.016941184089298, 16.0], [10.1735391616821...   \n",
       "19      19        10  [[7.016827583312988, 3.0], [7.817195415496826,...   \n",
       "\n",
       "                              top5  inTop5  \n",
       "0    [9.0, 10.0, 16.0, 17.0, 18.0]       1  \n",
       "1    [9.0, 10.0, 17.0, 18.0, 19.0]       1  \n",
       "2                     [10.0, 23.0]       1  \n",
       "3               [18.0, 20.0, 33.0]       0  \n",
       "4    [9.0, 16.0, 18.0, 19.0, 23.0]       0  \n",
       "5                     [10.0, 23.0]       1  \n",
       "6    [9.0, 10.0, 16.0, 23.0, 33.0]       0  \n",
       "7    [9.0, 10.0, 12.0, 17.0, 18.0]       1  \n",
       "8   [10.0, 16.0, 18.0, 19.0, 20.0]       1  \n",
       "9         [10.0, 18.0, 23.0, 24.0]       1  \n",
       "10   [9.0, 10.0, 16.0, 17.0, 18.0]       1  \n",
       "11         [9.0, 10.0, 23.0, 28.0]       1  \n",
       "12    [8.0, 9.0, 18.0, 20.0, 23.0]       0  \n",
       "13  [10.0, 16.0, 17.0, 18.0, 19.0]       1  \n",
       "14   [8.0, 10.0, 16.0, 18.0, 23.0]       1  \n",
       "15   [9.0, 10.0, 16.0, 18.0, 20.0]       1  \n",
       "16              [10.0, 18.0, 23.0]       1  \n",
       "17              [10.0, 18.0, 23.0]       0  \n",
       "18  [16.0, 18.0, 20.0, 23.0, 24.0]       0  \n",
       "19      [3.0, 5.0, 8.0, 9.0, 10.0]       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results, columns=[\"record\", \"original\", \"predict\"])\n",
    "\n",
    "def top5(x):\n",
    "    return np.array([y[1] for i,y in enumerate(x) if i < 5])\n",
    "\n",
    "def in_top_5(orig, top5):\n",
    "    return 1 if orig in top5 else 0\n",
    "\n",
    "df_results['top5'] = df_results['predict'].map(top5)\n",
    "df_results['inTop5'] = df_results.apply(lambda x: in_top_5(orig=x['original'], top5=x['top5']), axis=1)\n",
    "\n",
    "print(df_results['inTop5'].sum() / test_range)\n",
    "\n",
    "display(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
