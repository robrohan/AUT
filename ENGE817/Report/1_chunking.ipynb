{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feea0805",
   "metadata": {},
   "source": [
    "[Chunking](https://community.databricks.com/t5/technical-blog/the-ultimate-guide-to-chunking-strategies-for-rag-applications/ba-p/113089)\n",
    "- Fixed-Size Chunking (word, char or token counts (with overlaps))\n",
    "- Semantic Chunking (break at paragraphs or sentences)\n",
    "- Recursive Chunking\n",
    "- Adaptive Chunking\n",
    "- Context-Enriched Chunking\n",
    "- AI-Driven Dynamic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "67c784ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-text-splitters transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee17139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = None\n",
    "with open(\"./datasets/dsm.md\", 'r', encoding='utf-8') as f:\n",
    "    document = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84cce59",
   "metadata": {},
   "source": [
    "## Fixed-Size Chunking\n",
    "\n",
    "This is the simplest method. This splits based on a given character sequence, which defaults to \"\\n\\n\". Chunk length is measured by number of characters.\n",
    "\n",
    "1. How the text is split: by single character separator.\n",
    "2. How the chunk size is measured: by number of characters.\n",
    "\n",
    "To obtain the string content directly, use .split_text.\n",
    "To create LangChain Document objects (e.g., for use in downstream tasks), use .create_documents.\n",
    "\n",
    "https://python.langchain.com/docs/how_to/character_text_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f334fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
      "Created a chunk of size 653, which is longer than the specified 400\n",
      "Created a chunk of size 803, which is longer than the specified 400\n",
      "Created a chunk of size 416, which is longer than the specified 400\n",
      "Created a chunk of size 408, which is longer than the specified 400\n",
      "Created a chunk of size 478, which is longer than the specified 400\n",
      "Created a chunk of size 453, which is longer than the specified 400\n",
      "Created a chunk of size 472, which is longer than the specified 400\n",
      "Created a chunk of size 568, which is longer than the specified 400\n",
      "Created a chunk of size 635, which is longer than the specified 400\n",
      "Created a chunk of size 403, which is longer than the specified 400\n",
      "Created a chunk of size 453, which is longer than the specified 400\n",
      "Created a chunk of size 458, which is longer than the specified 400\n",
      "Created a chunk of size 1006, which is longer than the specified 400\n",
      "Created a chunk of size 584, which is longer than the specified 400\n",
      "Created a chunk of size 727, which is longer than the specified 400\n",
      "Created a chunk of size 803, which is longer than the specified 400\n",
      "Created a chunk of size 1136, which is longer than the specified 400\n",
      "Created a chunk of size 427, which is longer than the specified 400\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Load a tokenizer for a BERT-like model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    # separator=\"\\n\\n\",\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    # length_function=len,\n",
    "    length_function=count_tokens,\n",
    "    # is_separator_regex=False,\n",
    ")\n",
    "texts = text_splitter.create_documents([document])\n",
    "\n",
    "# print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1aaac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 416, which is longer than the specified 400\n",
      "Created a chunk of size 401, which is longer than the specified 400\n",
      "Created a chunk of size 473, which is longer than the specified 400\n",
      "Created a chunk of size 453, which is longer than the specified 400\n",
      "Created a chunk of size 458, which is longer than the specified 400\n",
      "Created a chunk of size 408, which is longer than the specified 400\n",
      "Created a chunk of size 478, which is longer than the specified 400\n",
      "Created a chunk of size 437, which is longer than the specified 400\n",
      "Created a chunk of size 403, which is longer than the specified 400\n",
      "Created a chunk of size 453, which is longer than the specified 400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "directory = \"./sections\"\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(directory, filename)) as f:\n",
    "            jsn = json.loads(f.read())\n",
    "            section = jsn[\"section\"]\n",
    "            texts = text_splitter.create_documents([section])\n",
    "            chunks = []\n",
    "            for i,t in enumerate(texts):\n",
    "                # replace newlines with spaces this can help keep word boundires\n",
    "                chunks.append(t.page_content.replace(\"\\n\", \" \"))\n",
    "            jsn[\"chunks\"] = chunks\n",
    "\n",
    "            with open(f'./chunks/{jsn[\"id\"]}.json', \"w\") as wf:\n",
    "                wf.write(json.dumps(jsn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f329669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,t in enumerate(texts):\n",
    "#     with open(f\"./chunks/{i}.txt\", \"w\") as f:\n",
    "#         f.write(t.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa728fd",
   "metadata": {},
   "source": [
    "## Semantic Chunking\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "1. How the text is split: by list of characters.\n",
    "2. How the chunk size is measured: by number of characters.\n",
    "\n",
    "Below we show example usage.\n",
    "\n",
    "To obtain the string content directly, use .split_text.\n",
    "\n",
    "To create LangChain Document objects (e.g., for use in downstream tasks), use .create_documents.\n",
    "\n",
    "https://python.langchain.com/docs/how_to/recursive_text_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22f01c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     # separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "#     chunk_size=1000,\n",
    "#     chunk_overlap=20,\n",
    "#     length_function=len,\n",
    "#     is_separator_regex=False,\n",
    "# )\n",
    "\n",
    "# texts = text_splitter.create_documents([document])\n",
    "# print(len(texts))\n",
    "\n",
    "# print(texts[0])\n",
    "\n",
    "# print(texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cbbe0",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b5100fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import re\n",
    "# from collections import Counter\n",
    "\n",
    "\n",
    "# def calculate_keyword_coverage(chunks, keywords):\n",
    "#     \"\"\"\n",
    "#     Calculate what percentage of keywords appear in at least one chunk.\n",
    "\n",
    "#     Args:\n",
    "#         chunks (list): List of text chunks\n",
    "#         keywords (list): List of keywords to search for\n",
    "\n",
    "#     Returns:\n",
    "#         float: Percentage of keywords covered (0-1)\n",
    "#     \"\"\"\n",
    "#     # Convert chunks to lowercase for case-insensitive matching\n",
    "#     lowercase_chunks = [chunk.lower() for chunk in chunks]\n",
    "#     lowercase_keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "#     # Count how many keywords appear in at least one chunk\n",
    "#     keywords_found = 0\n",
    "#     for keyword in lowercase_keywords:\n",
    "#         if any(keyword in chunk for chunk in lowercase_chunks):\n",
    "#             keywords_found += 1\n",
    "\n",
    "#     # Calculate coverage\n",
    "#     coverage = keywords_found / max(1, len(keywords))\n",
    "#     return coverage\n",
    "\n",
    "# def calculate_chunk_coherence(chunks):\n",
    "#     \"\"\"\n",
    "#     Calculate the average coherence of chunks based on sentence completeness.\n",
    "\n",
    "#     Args:\n",
    "#         chunks (list): List of text chunks\n",
    "\n",
    "#     Returns:\n",
    "#         float: Coherence score (0-1)\n",
    "#     \"\"\"\n",
    "#     # Count incomplete sentences at chunk boundaries\n",
    "#     incomplete_boundaries = 0\n",
    "\n",
    "#     for chunk in chunks:\n",
    "#         # Check if chunk starts with lowercase letter or continuation punctuation\n",
    "#         if chunk and (chunk[0].islower() or chunk[0] in ',;:)]}'):\n",
    "#             incomplete_boundaries += 1\n",
    "\n",
    "#         # Check if chunk ends without proper sentence-ending punctuation\n",
    "#         if chunk and not re.search(r'[.!?]\\s*$', chunk):\n",
    "#             incomplete_boundaries += 1\n",
    "\n",
    "#     # Calculate coherence (lower incomplete_boundaries = higher coherence)\n",
    "#     max_boundaries = len(chunks) * 2  # Start and end of each chunk\n",
    "#     coherence = 1 - (incomplete_boundaries / max(1, max_boundaries))\n",
    "#     return coherence\n",
    "\n",
    "# def calculate_concept_splitting(chunks, key_phrases):\n",
    "#     \"\"\"\n",
    "#     Calculate how often key phrases are split across chunks.\n",
    "\n",
    "#     Args:\n",
    "#         chunks (list): List of text chunks\n",
    "#         key_phrases (list): List of important phrases that should stay together\n",
    "\n",
    "#     Returns:\n",
    "#         float: Non-splitting score (0-1), higher is better\n",
    "#     \"\"\"\n",
    "#     # Count how many key phrases are split\n",
    "#     split_phrases = 0\n",
    "\n",
    "#     for phrase in key_phrases:\n",
    "#         phrase_lower = phrase.lower()\n",
    "\n",
    "#         # Check if phrase appears completely in any chunk\n",
    "#         complete_in_chunk = any(phrase_lower in chunk.lower() for chunk in chunks)\n",
    "\n",
    "#         # Check if parts of the phrase appear in different chunks\n",
    "#         words = phrase_lower.split()\n",
    "#         if len(words) > 1:\n",
    "#             parts_in_different_chunks = False\n",
    "\n",
    "#             for i in range(len(words) - 1):\n",
    "#                 part1 = \" \".join(words[:i+1])\n",
    "#                 part2 = \" \".join(words[i+1:])\n",
    "\n",
    "#                 for j, chunk1 in enumerate(chunks):\n",
    "#                     if part1 in chunk1.lower():\n",
    "#                         for chunk2 in chunks[j+1:]:\n",
    "#                             if part2 in chunk2.lower() and part1 not in chunk2.lower():\n",
    "#                                 parts_in_different_chunks = True\n",
    "#                                 break\n",
    "\n",
    "#             if parts_in_different_chunks and not complete_in_chunk:\n",
    "#                 split_phrases += 1\n",
    "\n",
    "#     # Calculate non-splitting score\n",
    "#     non_splitting = 1 - (split_phrases / max(1, len(key_phrases)))\n",
    "#     return non_splitting\n",
    "\n",
    "# def evaluate_chunking_strategies(document, keywords, key_phrases, chunking_strategies):\n",
    "#     \"\"\"\n",
    "#     Evaluates chunking strategies with custom metrics.\n",
    "\n",
    "#     Args:\n",
    "#         document (str): Document to chunk\n",
    "#         keywords (list): Important keywords for coverage metric\n",
    "#         key_phrases (list): Important phrases for concept splitting metric\n",
    "#         chunking_strategies (dict): Dictionary of chunking strategies with parameters\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: Results of the evaluation\n",
    "#     \"\"\"\n",
    "#     results = []\n",
    "\n",
    "#     for name, strategy in chunking_strategies.items():\n",
    "#         print(f\"Evaluating strategy: {name}\")\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         # Perform chunking based on strategy type\n",
    "#         if strategy[\"type\"] == \"fixed\":\n",
    "#             chunks = perform_fixed_size_chunking(\n",
    "#                 document,\n",
    "#                 chunk_size=strategy.get(\"size\", 1000),\n",
    "#                 chunk_overlap=strategy.get(\"overlap\", 0)\n",
    "#             )\n",
    "#         elif strategy[\"type\"] == \"semantic\":\n",
    "#             chunks = perform_semantic_chunking(\n",
    "#                 document,\n",
    "#                 chunk_size=strategy.get(\"size\", 500),\n",
    "#                 chunk_overlap=strategy.get(\"overlap\", 100)\n",
    "#             )\n",
    "#         elif strategy[\"type\"] == \"recursive\":\n",
    "#             chunks = perform_code_chunking(\n",
    "#                 document,\n",
    "#                 language=strategy.get(\"language\", \"python\"),\n",
    "#                 chunk_size=strategy.get(\"size\", 100),\n",
    "#                 chunk_overlap=strategy.get(\"overlap\", 15)\n",
    "#             )\n",
    "#         elif strategy[\"type\"] == \"adaptive\":\n",
    "#             chunks = perform_adaptive_chunking(\n",
    "#                 document,\n",
    "#                 min_size=strategy.get(\"min_size\", 300),\n",
    "#                 max_size=strategy.get(\"max_size\", 1000),\n",
    "#                 complexity_measure=strategy.get(\"complexity_measure\", \"combined\")\n",
    "#             )\n",
    "#         elif strategy[\"type\"] == \"context_enriched\":\n",
    "#             chunks = perform_context_enriched_chunking(\n",
    "#                 document,\n",
    "#                 chunk_size=strategy.get(\"size\", 500),\n",
    "#                 chunk_overlap=strategy.get(\"overlap\", 50),\n",
    "#                 window_size=strategy.get(\"window_size\", 1)\n",
    "#             )\n",
    "#         elif strategy[\"type\"] == \"ai_driven\":\n",
    "#             chunks = perform_ai_driven_chunking(\n",
    "#                 document,\n",
    "#                 max_chunks=strategy.get(\"max_chunks\", 10)\n",
    "#             )\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown chunking strategy type: {strategy['type']}\")\n",
    "\n",
    "#         # Record processing time\n",
    "#         processing_time = time.time() - start_time\n",
    "\n",
    "#         # Convert to text for evaluation if they're Document objects\n",
    "#         chunk_texts = []\n",
    "#         for chunk in chunks:\n",
    "#             if hasattr(chunk, 'page_content'):\n",
    "#                 chunk_texts.append(chunk.page_content)\n",
    "#             else:\n",
    "#                 chunk_texts.append(chunk)\n",
    "\n",
    "#         # Calculate custom metrics\n",
    "#         keyword_coverage = calculate_keyword_coverage(chunk_texts, keywords)\n",
    "#         chunk_coherence = calculate_chunk_coherence(chunk_texts)\n",
    "#         concept_integrity = calculate_concept_splitting(chunk_texts, key_phrases)\n",
    "\n",
    "#         # Calculate chunk statistics\n",
    "#         total_chunks = len(chunks)\n",
    "\n",
    "#         # Get chunk sizes\n",
    "#         if hasattr(chunks[0], 'page_content'):\n",
    "#             chunk_sizes = [len(chunk.page_content) for chunk in chunks]\n",
    "#         else:\n",
    "#             chunk_sizes = [len(chunk) for chunk in chunks]\n",
    "\n",
    "#         avg_chunk_size = sum(chunk_sizes) / len(chunk_sizes)\n",
    "#         chunk_size_std = (sum((size - avg_chunk_size) ** 2 for size in chunk_sizes) / len(chunk_sizes)) ** 0.5\n",
    "#         size_consistency = 1 - (chunk_size_std / max(1, avg_chunk_size))\n",
    "\n",
    "#         # Store results\n",
    "#         results.append({\n",
    "#             \"strategy\": name,\n",
    "#             \"processing_time\": round(processing_time, 2),\n",
    "#             \"keyword_coverage\": round(keyword_coverage, 2),\n",
    "#             \"chunk_coherence\": round(chunk_coherence, 2),\n",
    "#             \"concept_integrity\": round(concept_integrity, 2),\n",
    "#             \"size_consistency\": round(size_consistency, 2),\n",
    "#             \"total_chunks\": total_chunks,\n",
    "#             \"avg_chunk_size\": round(avg_chunk_size, 2)\n",
    "#         })\n",
    "\n",
    "#     # Convert to DataFrame\n",
    "#     results_df = pd.DataFrame(results)\n",
    "#     return results_df\n",
    "\n",
    "# def visualize_results(results_df):\n",
    "#     \"\"\"\n",
    "#     Creates visualizations of the evaluation results.\n",
    "\n",
    "#     Args:\n",
    "#         results_df (pd.DataFrame): Evaluation results\n",
    "#     \"\"\"\n",
    "#     # Set up the figure\n",
    "#     fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "#     # Plot processing time\n",
    "#     axs[0, 0].bar(results_df['strategy'], results_df['processing_time'])\n",
    "#     axs[0, 0].set_title('Processing Time (seconds)')\n",
    "#     axs[0, 0].set_ylabel('Time (s)')\n",
    "#     axs[0, 0].set_xticklabels(results_df['strategy'], rotation=45, ha='right')\n",
    "\n",
    "#     # Plot quality metrics\n",
    "#     axs[0, 1].bar(results_df['strategy'], results_df['keyword_coverage'])\n",
    "#     axs[0, 1].set_title('Keyword Coverage')\n",
    "#     axs[0, 1].set_ylabel('Score (0-1)')\n",
    "#     axs[0, 1].set_xticklabels(results_df['strategy'], rotation=45, ha='right')\n",
    "\n",
    "#     # Plot concept integrity\n",
    "#     axs[0, 2].bar(results_df['strategy'], results_df['concept_integrity'])\n",
    "#     axs[0, 2].set_title('Concept Integrity')\n",
    "#     axs[0, 2].set_ylabel('Score (0-1)')\n",
    "#     axs[0, 2].set_xticklabels(results_df['strategy'], rotation=45, ha='right')\n",
    "\n",
    "#     # Plot chunk coherence\n",
    "#     axs[1, 0].bar(results_df['strategy'], results_df['chunk_coherence'])\n",
    "#     axs[1, 0].set_title('Chunk Coherence')\n",
    "#     axs[1, 0].set_ylabel('Score (0-1)')\n",
    "#     axs[1, 0].set_xticklabels(results_df['strategy'], rotation=45, ha='right')\n",
    "\n",
    "#     # Plot total chunks\n",
    "#     axs[1, 1].bar(results_df['strategy'], results_df['total_chunks'])\n",
    "#     axs[1, 1].set_title('Total Number of Chunks')\n",
    "#     axs[1, 1].set_ylabel('Count')\n",
    "#     axs[1, 1].set_xticklabels(results_df['strategy'], rotation=45, ha='right')\n",
    "\n",
    "#     # Plot size consistency\n",
    "#     axs[1, 2].bar(results_df['strategy'], results_df['size_consistency'])\n",
    "#     axs[1, 2].set_title('Chunk Size Consistency')\n",
    "#     axs[1, 2].set_ylabel('Score (0-1)')\n",
    "#     axs[1, 2].set_xticklabels(results_df['strategy'], rotation=45, ha='right')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Create test document\n",
    "#     document = create_dummy_document()\n",
    "\n",
    "#     # Define important keywords for evaluation\n",
    "#     keywords = [\n",
    "#         \"machine learning\", \"supervised learning\", \"unsupervised learning\",\n",
    "#         \"neural networks\", \"LLMs\", \"fine-tuning\", \"pre-training\",\n",
    "#         \"reinforcement learning\", \"multimodal learning\", \"federated learning\",\n",
    "#         \"clustering\", \"classification\", \"regression\", \"PCA\"\n",
    "#     ]\n",
    "\n",
    "#     # Define key phrases that should remain together\n",
    "#     key_phrases = [\n",
    "#         \"Large Language Models\",\n",
    "#         \"Reinforcement Learning from Human Feedback\",\n",
    "#         \"Principal Component Analysis\",\n",
    "#         \"Support Vector Machines\",\n",
    "#         \"decision becomes more difficult\",\n",
    "#         \"train-test split\",\n",
    "#         \"natural language processing\"\n",
    "#     ]\n",
    "\n",
    "#     # Define chunking strategies to evaluate\n",
    "#     chunking_strategies = {\n",
    "#         \"fixed_500\": {\n",
    "#             \"type\": \"fixed\",\n",
    "#             \"size\": 500,\n",
    "#             \"overlap\": 0\n",
    "#         },\n",
    "#         \"fixed_500_overlap_100\": {\n",
    "#             \"type\": \"fixed\",\n",
    "#             \"size\": 500,\n",
    "#             \"overlap\": 100\n",
    "#         },\n",
    "#         \"semantic_500\": {\n",
    "#             \"type\": \"semantic\",\n",
    "#             \"size\": 500,\n",
    "#             \"overlap\": 100\n",
    "#         },\n",
    "#         \"adaptive_300_1000\": {\n",
    "#             \"type\": \"adaptive\",\n",
    "#             \"min_size\": 300,\n",
    "#             \"max_size\": 1000,\n",
    "#             \"complexity_measure\": \"combined\"\n",
    "#         },\n",
    "#         \"context_enriched_500\": {\n",
    "#             \"type\": \"context_enriched\",\n",
    "#             \"size\": 500,\n",
    "#             \"overlap\": 50,\n",
    "#             \"window_size\": 1\n",
    "#         },\n",
    "#         \"ai_driven_10\": {\n",
    "#             \"type\": \"ai_driven\",\n",
    "#             \"max_chunks\": 10\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     # Run evaluation\n",
    "#     results_df = evaluate_chunking_strategies(document, keywords, key_phrases, chunking_strategies)\n",
    "\n",
    "#     # Print results\n",
    "#     print(\"\\n----- EVALUATION RESULTS -----\")\n",
    "#     print(results_df)\n",
    "\n",
    "#     # Create visualizations\n",
    "#     try:\n",
    "#         visualize_results(results_df)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Visualization error: {e}\")\n",
    "\n",
    "#     # Export results to CSV\n",
    "#     results_df.to_csv(\"chunking_evaluation_results.csv\", index=False)\n",
    "#     print(\"\\nResults exported to 'chunking_evaluation_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
