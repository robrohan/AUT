{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5acd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: numpy in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.5)\n",
      "Requirement already satisfied: pandas in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: seaborn in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: pyfluidsynth in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.3.4)\n",
      "Requirement already satisfied: pretty_midi in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.2.10)\n",
      "Requirement already satisfied: matplotlib in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (3.10.3)\n",
      "Requirement already satisfied: filelock in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: mido>=1.1.16 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from pretty_midi->-r requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: six in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from pretty_midi->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 10)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 10)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 10)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 10)) (3.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693f9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gpt_mini.model import GPT\n",
    "from gpt_mini.trainer import Trainer\n",
    "from gpt_mini.bpe import MidiDataset\n",
    "import torch\n",
    "from gpt_mini.config import DEFAULT_DEVICE, CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80107acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.51M\n"
     ]
    }
   ],
   "source": [
    "model_config = GPT.get_default_config()\n",
    "# either model_type or (n_layer, n_head, n_embd) must be given in the config\n",
    "model_config.model_type = None # 'gpt-nano'\n",
    "model_config.n_layer = CONFIG[\"model\"][\"n_layer\"]\n",
    "model_config.n_head = CONFIG[\"model\"][\"n_head\"]\n",
    "model_config.n_embd = CONFIG[\"model\"][\"n_embed\"]\n",
    "# model_config.vocab_size = 50257 # 65535        # max number of vocabulary\n",
    "model_config.vocab_size = CONFIG[\"model\"][\"vocab_size\"]\n",
    "# model_config.block_size = 256                  # input context length\n",
    "model_config.block_size = CONFIG[\"model\"][\"block_size\"]\n",
    "\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6aaea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gpt_mini.bpe.MidiDataset object at 0x10820aa90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MidiDataset(\n",
    "    CONFIG[\"preprocess\"][\"new_dataset_index\"],\n",
    "    CONFIG[\"tokenizer\"][\"model\"],\n",
    "    CONFIG[\"model\"][\"block_size\"])\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ac302ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device mps\n"
     ]
    }
   ],
   "source": [
    "# your subclass of torch.utils.data.Dataset that emits example\n",
    "# torch LongTensor of lengths up to 1024, with integers from [0,50257)\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = CONFIG[\"training\"][\"learning_rate\"]\n",
    "train_config.max_iters = CONFIG[\"training\"][\"max_iters\"]\n",
    "train_config.batch_size = CONFIG[\"training\"][\"batch_size\"]\n",
    "train_config.num_workers = CONFIG[\"training\"][\"workers\"]\n",
    "train_config.device = DEFAULT_DEVICE\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ba67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robrohan/miniconda3/envs/comp838/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 10.85800\n",
      "iter_dt 1140.40ms; iter 100: train loss 7.22034\n",
      "iter_dt 1007.60ms; iter 200: train loss 7.41551\n",
      "iter_dt 1009.08ms; iter 300: train loss 6.20288\n",
      "iter_dt 995.15ms; iter 400: train loss 6.55572\n",
      "iter_dt 1012.83ms; iter 500: train loss 6.24002\n",
      "iter_dt 1005.59ms; iter 600: train loss 5.83739\n",
      "iter_dt 1009.72ms; iter 700: train loss 5.52698\n",
      "iter_dt 1008.25ms; iter 800: train loss 5.04322\n",
      "iter_dt 1010.18ms; iter 900: train loss 5.26122\n",
      "iter_dt 1007.90ms; iter 1000: train loss 5.43129\n",
      "iter_dt 1012.55ms; iter 1100: train loss 4.55850\n",
      "iter_dt 1007.60ms; iter 1200: train loss 4.42262\n",
      "iter_dt 1007.78ms; iter 1300: train loss 4.54551\n",
      "iter_dt 1201.49ms; iter 1400: train loss 4.43930\n",
      "iter_dt 1035.96ms; iter 1500: train loss 4.19912\n",
      "iter_dt 1027.37ms; iter 1600: train loss 4.19620\n",
      "iter_dt 1006.98ms; iter 1700: train loss 4.12743\n",
      "iter_dt 1024.13ms; iter 1800: train loss 3.76660\n",
      "iter_dt 1019.40ms; iter 1900: train loss 4.19826\n"
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "        # Save checkpoints\n",
    "        torch.save(\n",
    "            trainer.model.state_dict(),\n",
    "            f\"./checkpoints/gpt_{trainer.iter_num}.pt\")\n",
    "\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp838",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
