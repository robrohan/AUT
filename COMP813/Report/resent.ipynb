{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df7890a",
   "metadata": {},
   "source": [
    "# \"ResNet-8\" Classifier\n",
    "\n",
    "- [Training Dataset](https://huggingface.co/datasets/uoft-cs/cifar10)\n",
    "- [Corrupt Dataset](https://huggingface.co/datasets/robro/cifar10-c-parquet)\n",
    "\n",
    "```\n",
    "@article{\n",
    "    hendrycks2019benchmarking, \n",
    "    title={Benchmarking neural network robustness to common corruptions and perturbations}, \n",
    "    author={Hendrycks, Dan and Dietterich, Thomas}, \n",
    "    journal={arXiv preprint arXiv:1903.12261}, \n",
    "    year={2019} \n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "- Dataaset [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "- https://debuggercafe.com/building-resnets-from-scratch-using-pytorch/\n",
    "- https://towardsdev.com/implement-resnet-with-pytorch-a9fb40a77448"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f399b8",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "beb835fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: matplotlib in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (3.10.5)\n",
      "Requirement already satisfied: numpy in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: tqdm in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: datasets in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: torchinfo in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: filelock in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision matplotlib numpy scikit-learn tqdm pandas datasets torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e01e7",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c8a15c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5750f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4163d50",
   "metadata": {},
   "source": [
    "## Load CIFAR10-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4c8084bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     img  label\n",
       "0      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      0\n",
       "1      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      6\n",
       "2      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      0\n",
       "3      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      2\n",
       "4      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      7\n",
       "...                                                  ...    ...\n",
       "49995  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      3\n",
       "49996  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      9\n",
       "49997  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      1\n",
       "49998  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      1\n",
       "49999  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>corruption_name</th>\n",
       "      <th>corruption_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>3</td>\n",
       "      <td>zoom_blur</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>8</td>\n",
       "      <td>zoom_blur</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>8</td>\n",
       "      <td>zoom_blur</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>0</td>\n",
       "      <td>zoom_blur</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>6</td>\n",
       "      <td>zoom_blur</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>8</td>\n",
       "      <td>brightness</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>3</td>\n",
       "      <td>brightness</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>5</td>\n",
       "      <td>brightness</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>1</td>\n",
       "      <td>brightness</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>7</td>\n",
       "      <td>brightness</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    image  label  \\\n",
       "0       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      3   \n",
       "1       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      8   \n",
       "2       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      8   \n",
       "3       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      0   \n",
       "4       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      6   \n",
       "...                                                   ...    ...   \n",
       "949995  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      8   \n",
       "949996  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      3   \n",
       "949997  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5   \n",
       "949998  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      1   \n",
       "949999  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      7   \n",
       "\n",
       "       corruption_name  corruption_level  \n",
       "0            zoom_blur                 1  \n",
       "1            zoom_blur                 1  \n",
       "2            zoom_blur                 1  \n",
       "3            zoom_blur                 1  \n",
       "4            zoom_blur                 1  \n",
       "...                ...               ...  \n",
       "949995      brightness                 5  \n",
       "949996      brightness                 5  \n",
       "949997      brightness                 5  \n",
       "949998      brightness                 5  \n",
       "949999      brightness                 5  \n",
       "\n",
       "[950000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import io\n",
    "\n",
    "t_dataset = load_dataset(\"uoft-cs/cifar10\", split=\"train\", trust_remote_code=False)\n",
    "r_dataset = load_dataset(\"robro/cifar10-c-parquet\", split=\"train\", trust_remote_code=False)\n",
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\",]\n",
    "\n",
    "# def decode_bytes_to_pil(col: str):\n",
    "#     def make_image(ds):\n",
    "#         # if \"bytes\" in ds[col]:\n",
    "#             # ds[col] = Image.open(io.BytesIO(ds[col][\"bytes\"]))\n",
    "#         ds[col] = Image.open(ds[col])\n",
    "#         return ds\n",
    "#     return make_image\n",
    "# t_dataset = t_dataset.map(decode_bytes_to_pil(\"img\"))\n",
    "# r_dataset = r_dataset.map(decode_bytes_to_pil(\"image\"))\n",
    "\n",
    "t_df_dataset = t_dataset.to_pandas()\n",
    "r_df_dataset = r_dataset.to_pandas()\n",
    "\n",
    "display(t_df_dataset)\n",
    "display(r_df_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "57d74385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDzjSYJ7fUzLANrx/NufgAd/rXZR3xvn8y9LNbI64hjGdwA6n61tSeHLLT0MmoY3AZXLHj2AqhpUS3cEuqW9uJIrOR1mnc8EjooX2HevHcvaPRbHZ9UhGzkzsf7d+yRRFImjUJ8qOuAB9O1bUGt2UoUGSLeRnbuFeBavNf3+pWxtYZNrHYZFQhXye/rWs3hrVdVlkuLHZJ5TeXy+3kdQPaj6utrmNSmuT3VsTeLNZvNavLm4ztjXLYz93HpUmgahZ6P4I8rUbyQNdyvN9miOSynoT6ZxXn802ofZz+7naDPVgQDUQllz/pJKhR0biuxUvdtc0dT3k7HW3niwXs8Fsf9C0/cA5j5fb6A/wCFekaP4p8MixhstOdI4UHCHhvc+prwCSUSyhgwCjgCplkLDqMjoc1pHDRUdNDOVeTep//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: frog\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "example = t_df_dataset.iloc[1]\n",
    "image = example[\"img\"]\n",
    "label = example[\"label\"]\n",
    "\n",
    "stream = io.BytesIO(image['bytes'])\n",
    "img = Image.open(stream)\n",
    "\n",
    "display(img)\n",
    "print(f\"Label: {classes[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2098ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # Define a function to convert PIL images to tensors\n",
    "# def transform_to_tensor(row):\n",
    "#     if isinstance(row[\"img\"], dict) and \"bytes\" in row[\"img\"]:\n",
    "#         img = Image.open(io.BytesIO(row[\"img\"][\"bytes\"]))\n",
    "#     elif isinstance(row[\"img\"], bytes):\n",
    "#         img = Image.open(io.BytesIO(row[\"img\"]))\n",
    "#     else:\n",
    "#         img = row[\"img\"]\n",
    "#     row[\"pixel_values\"] = transforms.ToTensor()(img)\n",
    "#     return row\n",
    "\n",
    "# # Function to calculate mean and std\n",
    "# def calculate_mean_std(dataset):\n",
    "#     # Stack all the tensors in the dataset into a single 4D tensor of shape (num_images, 3, 32, 32).\n",
    "#     pixel_values = [example[\"pixel_values\"] for example in dataset]\n",
    "#     all_images = torch.stack(pixel_values)\n",
    "#     # Calculate mean and std for each channel (R, G, B)\n",
    "#     mean = all_images.mean(dim=[0, 2, 3])  # Mean over batch, height, width\n",
    "#     std = all_images.std(dim=[0, 2, 3])    # Std over batch, height, width\n",
    "#     return mean, std\n",
    "\n",
    "# t_dataset = t_dataset.map(transform_to_tensor)\n",
    "# # display(t_dataset.to_pandas())\n",
    "# mean, std = calculate_mean_std(t_dataset)\n",
    "\n",
    "# print(\"Mean:\", mean)\n",
    "# print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba0c8a",
   "metadata": {},
   "source": [
    "### Augment Dataset\n",
    "\n",
    "Here we are augmenting the training dataset with some slight tweaks to better train the model (flipping, etc). This helps the model become more robust to small variations, which is good generalization (we can remove this if needed).\n",
    "\n",
    "We **do not** augment the curropt dataset, but we do normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa56f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Data augmentation artificially expands the training set by creating\n",
    "# plausible variations of the input images. This reduces overfitting and\n",
    "# improves generalization for small datasets.\n",
    "# Should we do this?\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize(mean, std): Normalizes the tensor using the mean and standard\n",
    "    # deviation of the CIFAR-10 dataset. The values (0.4914, 0.4822, 0.4465)\n",
    "    # and (0.2023, 0.1994, 0.2010) are precomputed for CIFAR-10.\n",
    "    # Need to calulate these myself...\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Apply to datasets\n",
    "t_dataset.set_transform(lambda x: {\"pixel_values\": train_transform(x[\"img\"]), \"labels\": x[\"label\"]})\n",
    "r_dataset.set_transform(lambda x: {\"pixel_values\": test_transform(x[\"image\"]), \"labels\": x[\"label\"]})\n",
    "\n",
    "\n",
    "\n",
    "# Convert to PyTorch Dataset\n",
    "def transform_fn(examples):\n",
    "    examples[\"pixel_values\"] = [train_transform(image.convert(\"RGB\")) for image in examples[\"img\"]]\n",
    "    examples[\"labels\"] = [int(label) for label in examples[\"label\"]]\n",
    "    return examples\n",
    "\n",
    "t_dataset.set_transform(transform_fn)\n",
    "\n",
    "# Create DataLoader\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    return pixel_values, labels\n",
    "\n",
    "train_loader = DataLoader(t_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8adae",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0a921",
   "metadata": {},
   "source": [
    "ResNet-8:\n",
    "\n",
    "- Input: 32x32 (CIFAR-10)\n",
    "- Channels: 16 → 32 → 64\n",
    "- Blocks: 2 per stage (total 6 blocks + initial conv)\n",
    "- Parameters: ~0.3M–0.7M (can adjust channels to match ViT-Tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "09306e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5d010",
   "metadata": {},
   "source": [
    "There are 3 main components that make up the ResNet.\n",
    "\n",
    "1. input layer (conv1 + max pooling) (Usually referred to as layer 0)\n",
    "2. ResBlocks (conv2 without max pooing ~ conv5) (Usually referred to as layer1 ~ layer4)\n",
    "3. final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fb2d255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7cc1bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet8(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 16  # Start with 16 channels\n",
    "\n",
    "        # Initial conv layer\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Two layers per stage, with channel doubling each stage\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)  # 16 channels\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)  # 32 channels\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)  # 64 channels\n",
    "\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)  # Global average pool for 32x32 input\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "45ab63b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet8                                  [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 16, 32, 32]           432\n",
       "├─BatchNorm2d: 1-2                       [1, 16, 32, 32]           32\n",
       "├─Sequential: 1-3                        [1, 16, 32, 32]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 16, 32, 32]           2,304\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 16, 32, 32]           32\n",
       "│    │    └─Conv2d: 3-3                  [1, 16, 32, 32]           2,304\n",
       "│    │    └─BatchNorm2d: 3-4             [1, 16, 32, 32]           32\n",
       "│    │    └─Sequential: 3-5              [1, 16, 32, 32]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-6                  [1, 16, 32, 32]           2,304\n",
       "│    │    └─BatchNorm2d: 3-7             [1, 16, 32, 32]           32\n",
       "│    │    └─Conv2d: 3-8                  [1, 16, 32, 32]           2,304\n",
       "│    │    └─BatchNorm2d: 3-9             [1, 16, 32, 32]           32\n",
       "│    │    └─Sequential: 3-10             [1, 16, 32, 32]           --\n",
       "├─Sequential: 1-4                        [1, 32, 16, 16]           --\n",
       "│    └─BasicBlock: 2-3                   [1, 32, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-11                 [1, 32, 16, 16]           4,608\n",
       "│    │    └─BatchNorm2d: 3-12            [1, 32, 16, 16]           64\n",
       "│    │    └─Conv2d: 3-13                 [1, 32, 16, 16]           9,216\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 32, 16, 16]           64\n",
       "│    │    └─Sequential: 3-15             [1, 32, 16, 16]           576\n",
       "│    └─BasicBlock: 2-4                   [1, 32, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-16                 [1, 32, 16, 16]           9,216\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 32, 16, 16]           64\n",
       "│    │    └─Conv2d: 3-18                 [1, 32, 16, 16]           9,216\n",
       "│    │    └─BatchNorm2d: 3-19            [1, 32, 16, 16]           64\n",
       "│    │    └─Sequential: 3-20             [1, 32, 16, 16]           --\n",
       "├─Sequential: 1-5                        [1, 64, 8, 8]             --\n",
       "│    └─BasicBlock: 2-5                   [1, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-21                 [1, 64, 8, 8]             18,432\n",
       "│    │    └─BatchNorm2d: 3-22            [1, 64, 8, 8]             128\n",
       "│    │    └─Conv2d: 3-23                 [1, 64, 8, 8]             36,864\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 64, 8, 8]             128\n",
       "│    │    └─Sequential: 3-25             [1, 64, 8, 8]             2,176\n",
       "│    └─BasicBlock: 2-6                   [1, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-26                 [1, 64, 8, 8]             36,864\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 64, 8, 8]             128\n",
       "│    │    └─Conv2d: 3-28                 [1, 64, 8, 8]             36,864\n",
       "│    │    └─BatchNorm2d: 3-29            [1, 64, 8, 8]             128\n",
       "│    │    └─Sequential: 3-30             [1, 64, 8, 8]             --\n",
       "├─Linear: 1-6                            [1, 10]                   650\n",
       "==========================================================================================\n",
       "Total params: 175,258\n",
       "Trainable params: 175,258\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 26.66\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 2.29\n",
       "Params size (MB): 0.70\n",
       "Estimated Total Size (MB): 3.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "resnet8 = ResNet8(10).to(device)\n",
    "summary(resnet8, (1, 3, 32, 32))  # Batch size of 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
