{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563ab2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube2 in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (15.0.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-ffmpeg in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (2.0.12)\n",
      "Requirement already satisfied: pyee in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from python-ffmpeg) (13.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/robrohan/miniconda3/envs/spikes/lib/python3.11/site-packages (from python-ffmpeg) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip uninstall pytube -y\n",
    "%pip install pytube2\n",
    "%pip install python-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7cca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube.download_helper import (\n",
    "    download_videos_from_channels,\n",
    "    download_video,\n",
    "    download_videos_from_list,\n",
    ")\n",
    "# download_videos_from_channels(channels=[\"channel1\", \"channel2\"])\n",
    "# download_videos_from_list(filename=\"videos.txt\")\n",
    "# download_video(url=\"https://www.youtube.com/watch?v=9Zk_hY_CjiE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4545c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ffmpeg import FFmpeg\n",
    "\n",
    "input_video=\"videos/Neuroevolution_Explained_by_Example.mp4\"\n",
    "output_audio=\"videos/audio1.wav\"\n",
    "\n",
    "ffmpeg = (\n",
    "    FFmpeg()\n",
    "    .option(\"y\")\n",
    "    .input(input_video)\n",
    "    .output(\n",
    "        output_audio,\n",
    "        {\"ar:\": \"16000\", \"ac\": \"1\", \"c:a\": \"pcm_s16le\"},\n",
    "    )\n",
    ")\n",
    "ffmpeg.execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16fc3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_with_params_no_state: loading model from 'models/ggml-base.en.bin'\n",
      "whisper_init_with_params_no_state: use gpu    = 1\n",
      "whisper_init_with_params_no_state: flash attn = 0\n",
      "whisper_init_with_params_no_state: gpu_device = 0\n",
      "whisper_init_with_params_no_state: dtw        = 0\n",
      "whisper_init_with_params_no_state: devices    = 3\n",
      "whisper_init_with_params_no_state: backends   = 3\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51864\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 512\n",
      "whisper_model_load: n_audio_head  = 8\n",
      "whisper_model_load: n_audio_layer = 6\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 512\n",
      "whisper_model_load: n_text_head   = 8\n",
      "whisper_model_load: n_text_layer  = 6\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 2 (base)\n",
      "whisper_model_load: adding 1607 extra tokens\n",
      "whisper_model_load: n_langs       = 99\n",
      "whisper_model_load:        Metal total size =   147.37 MB\n",
      "whisper_model_load: model size    =  147.37 MB\n",
      "whisper_backend_init_gpu: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M3\n",
      "ggml_metal_init: picking default device: Apple M3\n",
      "ggml_metal_load_library: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M3\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 17179.89 MB\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "whisper_backend_init: using BLAS backend\n",
      "whisper_init_state: kv self size  =    6.29 MB\n",
      "whisper_init_state: kv cross size =   18.87 MB\n",
      "whisper_init_state: kv pad  size  =    3.15 MB\n",
      "whisper_init_state: compute buffer (conv)   =   17.24 MB\n",
      "whisper_init_state: compute buffer (encode) =   85.88 MB\n",
      "whisper_init_state: compute buffer (cross)  =    4.66 MB\n",
      "whisper_init_state: compute buffer (decode) =   97.29 MB\n",
      "\n",
      "system_info: n_threads = 4 / 8 | WHISPER : COREML = 0 | OPENVINO = 0 | Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | ACCELERATE = 1 | REPACK = 1 | \n",
      "\n",
      "main: processing 'videos/audio1.wav' (7869521 samples, 491.8 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = en, task = transcribe, timestamps = 1 ...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[00:00:00.000 --> 00:00:05.600]   This is an AI agent, and this is a virtual obstacle course.\n",
      "[00:00:05.600 --> 00:00:10.600]   The AI has one goal, to complete the course as fast as possible.\n",
      "[00:00:10.600 --> 00:00:13.000]   Here is the solution it came up with.\n",
      "[00:00:27.000 --> 00:00:35.000]   It's not exactly the most elegant path to the goal, but it's still impressive considering this AI agent started with zero knowledge.\n",
      "[00:00:35.000 --> 00:00:36.000]   Let me explain.\n",
      "[00:00:36.000 --> 00:00:47.000]   This AI was trained using a technique called neuroevolution, and just like the name suggests, it has to do with the evolving brains, specifically neural network brains.\n",
      "[00:00:47.000 --> 00:00:53.000]   I'm sure that some of you are familiar with these, but for those of you who are not, here's a brief rundown.\n",
      "[00:00:53.000 --> 00:00:56.000]   In many ways, neural networks are like real brains.\n",
      "[00:00:56.000 --> 00:01:04.000]   Both have neurons that receive and transmit information to other neurons, and both have connections with different levels of strength.\n",
      "[00:01:04.000 --> 00:01:11.000]   The major difference is that real brains operate using complicated chemistry and electricity, while neural networks just use numbers.\n",
      "[00:01:11.000 --> 00:01:16.000]   For example, a single neuron in a neural network receives input data as numbers.\n",
      "[00:01:16.000 --> 00:01:21.000]   These numbers are multiplied by their respective connection weights before being summed together.\n",
      "[00:01:21.000 --> 00:01:27.000]   The neuron applies an activation function, and then passes on the data through outgoing connections.\n",
      "[00:01:27.000 --> 00:01:30.000]   We can group these neurons into layers.\n",
      "[00:01:30.000 --> 00:01:39.000]   One of these layers is called the input layer, where we feed in information to the network, and one is called the output layer, where we receive the network's calculation.\n",
      "[00:01:39.000 --> 00:01:47.000]   This particular type of neural network is called a feed-forward network, since all of the information flows in just one direction.\n",
      "[00:01:47.000 --> 00:01:51.000]   And, in case you were curious, here's what the previous agent's brain looks like.\n",
      "[00:01:51.000 --> 00:01:55.000]   It only needed 12 neurons to finish the obstacle course.\n",
      "[00:01:55.000 --> 00:01:58.000]   So that's the neural part of neural evolution.\n",
      "[00:01:58.000 --> 00:02:03.000]   The evolution part has to do with the way we train the network to solve the problem.\n",
      "[00:02:03.000 --> 00:02:08.000]   We'll be using genetic algorithms, a technique inspired by natural selection.\n",
      "[00:02:08.000 --> 00:02:15.000]   I actually covered genetic algorithms in detail in the previous video of the series, but here's a quick recap.\n",
      "[00:02:15.000 --> 00:02:28.000]   A genetic algorithm allows us to take a pool of possible solutions, select the best according to a fitness function, and create a new generation of solutions by combining and mutating the top performers.\n",
      "[00:02:28.000 --> 00:02:32.000]   This whole procedure is repeated until the problem is solved.\n",
      "[00:02:32.000 --> 00:02:38.000]   In order to make this technique work with neural networks, we need a way to convert them into genetic code.\n",
      "[00:02:38.000 --> 00:02:53.000]   Provided that the structure of our neural networks don't change, all we need to do is convert each weight in the network into a binary number, arrange them in a consistent order, and just like that, we have a genetic representation that we can plug into the genetic algorithm.\n",
      "[00:02:53.000 --> 00:03:01.000]   Now that we have a good idea of how neural evolution works, let me tell you a little bit more about the obstacle course from before.\n",
      "[00:03:01.000 --> 00:03:07.000]   During training, I had 64 agents simultaneously going through the course each generation.\n",
      "[00:03:07.000 --> 00:03:10.000]   Their only goal was to reach the finish line to the far right.\n",
      "[00:03:10.000 --> 00:03:14.000]   To get there, they needed to get past the obstacles along the way.\n",
      "[00:03:14.000 --> 00:03:22.000]   To achieve this, each agent is equipped with some senses, three sight lines, and an internal compass pointing towards the exit.\n",
      "[00:03:22.000 --> 00:03:24.000]   Let me show you the training footage.\n",
      "[00:03:31.000 --> 00:03:56.000]   [Music]\n",
      "[00:03:56.000 --> 00:04:24.000]   [Music]\n",
      "[00:04:26.000 --> 00:04:51.000]   [Music]\n",
      "[00:04:51.000 --> 00:05:16.000]   [Music]\n",
      "[00:05:16.000 --> 00:05:44.000]   [Music]\n",
      "[00:05:44.000 --> 00:06:12.000]   [Music]\n",
      "[00:06:12.000 --> 00:06:37.000]   [Music]\n",
      "[00:06:37.000 --> 00:07:02.000]   [Music]\n",
      "[00:07:02.000 --> 00:07:19.000]   [Music]\n",
      "[00:07:19.000 --> 00:07:28.000]   As you can see, after some time, the agents become pretty good at navigating the course, even though their style of locomotion is unique.\n",
      "[00:07:28.000 --> 00:07:36.000]   Of course, for more difficult problems, we would need to use bigger and more complex neural networks, or change our approach entirely.\n",
      "[00:07:36.000 --> 00:07:45.000]   The specific type of neural evolution we've been using is called conventional neural evolution, and it's where we only evolved the connection weights in the network.\n",
      "[00:07:45.000 --> 00:07:50.000]   There are many techniques that can also evolve the structure and size of the network as well.\n",
      "[00:07:50.000 --> 00:07:55.000]   This means that the AI could more easily optimize its brain to solve the problem.\n",
      "[00:07:55.000 --> 00:08:03.000]   In a future video, I'll be taking a look at NEET, an algorithm that can achieve this. See you then.\n",
      "[00:08:03.000 --> 00:08:11.000]   [Music]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "output_lrc: saving output to 'videos/audio1.wav.lrc'\n",
      "\n",
      "whisper_print_timings:     load time =    82.98 ms\n",
      "whisper_print_timings:     fallbacks =   1 p /   0 h\n",
      "whisper_print_timings:      mel time =   142.12 ms\n",
      "whisper_print_timings:   sample time =   888.20 ms /  4671 runs (     0.19 ms per run)\n",
      "whisper_print_timings:   encode time =  1579.52 ms /    19 runs (    83.13 ms per run)\n",
      "whisper_print_timings:   decode time =    79.69 ms /    30 runs (     2.66 ms per run)\n",
      "whisper_print_timings:   batchd time =  3111.00 ms /  4542 runs (     0.68 ms per run)\n",
      "whisper_print_timings:   prompt time =   358.41 ms /  4048 runs (     0.09 ms per run)\n",
      "whisper_print_timings:    total time =  6438.70 ms\n",
      "ggml_metal_free: deallocating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/Users/robrohan/Projects/SideProjects/whisper.cpp/build/bin/whisper-cli', '--output-lrc', '-f', 'videos/audio1.wav'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\n",
    "    \"/Users/robrohan/Projects/SideProjects/whisper.cpp/build/bin/whisper-cli\",\n",
    "    \"--output-lrc\",\n",
    "    \"-f\",\n",
    "    \"videos/audio1.wav\",\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
